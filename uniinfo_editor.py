import argparse
import csv
import itertools
import logging
import re
import shlex
from collections.abc import Iterator
from datetime import datetime
from pathlib import Path
from typing import Literal, NamedTuple

import chardet
from prompt_toolkit import PromptSession
from prompt_toolkit.completion import Completer, Completion
from rich.console import Console
from rich.logging import RichHandler
from rich.table import Table


def setup_logger() -> logging.Logger:
    logger = logging.getLogger('uniinfo')
    logger.setLevel(logging.DEBUG)
    logger.handlers.clear()

    # === ç»ˆç«¯è¾“å‡ºï¼Œç”¨ RichHandler ===
    ch = RichHandler(
        rich_tracebacks=True, markup=True, show_time=False, show_path=False
    )
    ch.setLevel(logging.DEBUG)  # æ§åˆ¶å°æ˜¾ç¤ºçº§åˆ«
    ch.setFormatter(logging.Formatter('%(message)s'))  # Rich è¦ç”¨ message

    # === æ–‡ä»¶æ—¥å¿—è¾“å‡ºï¼Œç”¨æ™®é€š Formatter ===
    now_str = datetime.now().strftime('%Y-%m-%d_%H-%M')
    filename = f'uniinfo - {now_str}.log'
    fh = logging.FileHandler(filename, encoding='utf-8')
    fh.setLevel(logging.DEBUG)
    fh.setFormatter(logging.Formatter('%(levelname)s:  %(message)s'))

    # === ç»‘å®š handler ===
    logger.addHandler(ch)
    logger.addHandler(fh)
    return logger


def scan_folders(*folders: str) -> dict[str, Path]:
    pattern = {'.csv', '.txt'}

    if not folders:
        folders = ('university-information', 'questionnaires')

    gens: list[Iterator[Path]] = [
        Path(folder).rglob('*')
        for folder in folders
        if Path(folder).exists() and Path(folder).is_dir()
    ]

    ret: dict[str, Path] = {}
    for file in itertools.chain(*gens):
        if file.suffix in pattern:
            # later same-name files will be overridden by last encountered
            ret[file.name] = file
    return ret


class CommandCompleter(Completer):
    def __init__(self, commands: list[str], file_names: list[str] = None):
        self.commands = commands
        self.file_names = file_names or []

    def update_files(self, files: list[str]):
        self.file_names = files

    def get_completions(self, document, complete_event):
        # ä¿ç•™åŸå§‹ textï¼ˆä¸è¦ stripï¼Œéœ€æ£€æµ‹æœ«å°¾ç©ºæ ¼ï¼‰
        text = document.text_before_cursor.lower()

        # 1) ç©ºè¾“å…¥æˆ–ä»…ç©ºç™½ -> åˆ—å‡ºæ‰€æœ‰å‘½ä»¤
        if text == '' or text.isspace():
            for cmd in self.commands:
                # start_position=0 è¡¨ç¤ºä»å½“å‰ä½ç½®æ’å…¥å®Œæ•´å‘½ä»¤
                yield Completion(cmd, start_position=0)
            return

        # æ£€æŸ¥æ˜¯å¦ä»¥ç©ºæ ¼ç»“å°¾ï¼ˆç”¨äºåˆ¤æ–­ç”¨æˆ·æ˜¯å¦å·²å¼€å§‹æ–°å‚æ•°ï¼‰
        ends_with_space = text.endswith(' ')

        # å°è¯• shell é£æ ¼åˆ‡åˆ†ï¼ˆå¤„ç†å¼•å·ï¼‰
        try:
            parts = shlex.split(text)
        except ValueError:
            # unmatched quotes ç­‰è§£æé”™è¯¯æ—¶ï¼Œä¸è¿”å›è¡¥å…¨
            return

        # 2) ä»åœ¨è¾“å…¥ç¬¬ä¸€ä¸ªå•è¯ï¼ˆå‘½ä»¤ï¼‰
        if ' ' not in text:
            prefix = text
            for cmd in self.commands:
                if cmd.lower().startswith(prefix):
                    yield Completion(cmd, start_position=-len(prefix))
            return

        # 3) å·²è¾“å…¥å‘½ä»¤ä¸”è¿›å…¥å‚æ•°è¡¥å…¨é˜¶æ®µ
        cmd = parts[0] if parts else ''
        # å·²è¾“å…¥çš„å‚æ•°ï¼ˆæ–‡ä»¶åï¼‰åˆ—è¡¨
        used_files = parts[1:] if len(parts) > 1 else []

        # å¦‚æœå·²ç»è¾“å…¥ 2 ä¸ªæˆ–ä»¥ä¸Šå‚æ•°ï¼ˆè¾¾åˆ°ä¸Šé™ï¼‰ï¼Œä¸å†æä¾›æ–‡ä»¶è¡¥å…¨
        if len(used_files) >= 2:
            return

        # ç¡®å®šå½“å‰æ­£åœ¨è¾“å…¥çš„è¯ï¼ˆè‹¥ä»¥ç©ºæ ¼ç»“å°¾åˆ™è¡¨ç¤ºæ­£åœ¨æ–°å»ºå‚æ•°ï¼Œlast_word ä¸ºç©ºï¼‰
        last_word = ''
        if not ends_with_space:
            # WORD=True å…è®¸æŠŠè¿å­—ç¬¦ç­‰ä¹Ÿä½œä¸ºè¯çš„ä¸€éƒ¨åˆ†ï¼ŒæŒ‰éœ€å¯æ”¹ä¸º False
            last_word = document.get_word_before_cursor(WORD=True) or ''

        # åªæœ‰ load/dump æ”¯æŒæ–‡ä»¶åè¡¥å…¨
        if cmd in ('load', 'dump'):
            for fname in self.file_names:
                if fname in used_files:
                    continue  # æ’é™¤å·²è¾“å…¥çš„æ–‡ä»¶
                # å¦‚æœæ²¡æœ‰éƒ¨åˆ†å‰ç¼€ï¼ˆlast_word == ''ï¼‰ï¼Œå°±æ˜¾ç¤ºæ‰€æœ‰å‰©ä½™æ–‡ä»¶
                if last_word == '' or fname.startswith(last_word):
                    yield Completion(fname, start_position=-len(last_word))


def smart_path(p: Path) -> str:
    path = p.resolve()
    try:
        # å°è¯•ç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•
        return str(path.relative_to(Path.cwd()))
    except ValueError:
        # æ— æ³•ç›¸å¯¹å½“å‰ç›®å½•ï¼Œè¿”å›ç»å¯¹è·¯å¾„
        return str(path)


type ID = str
type IssueId = list[str] | None
type Changed = Literal['del', 'outdate']
commands = [
    ('load [data1 data2]', 'åŠ è½½æ•°æ®æ–‡ä»¶ï¼ˆé»˜è®¤è‡ªåŠ¨æœå¯»å½“å‰ç›®å½•.csvå’Œ.txtï¼‰'),
    ('dump [newData] [newData]', 'å¯¼å‡ºæ•°æ®æ–‡ä»¶ï¼ˆé»˜è®¤è¦†å†™ï¼‰'),
    ('alias oldName newName [issueId...]', 'å­¦æ ¡æ›´åï¼ˆè®°å½•åˆ«å/æ›´åï¼‰'),
    ('del ID [issueId...]', 'åˆ é™¤è®°å½•'),
    ('outdate ID [issueId...]', 'æ ‡è®°è¿‡æœŸ'),
    ('view ID [ID ...]', 'æŸ¥çœ‹è®°å½•'),
    ('exit', 'é€€å‡ºç¨‹åº'),
    ('generate', 'ç”Ÿæˆä¿®æ”¹æ—¥å¿—ï¼ˆMarkdownæ ¼å¼ï¼‰'),
]


class Stuffs(NamedTuple):
    issue_ids: IssueId
    changed: Changed


class UniInfoCLI:
    def __init__(self):
        self.commands = [
            *[cmd.split()[0] for cmd, _ in commands],
            '?',
        ]
        self.completer = CommandCompleter(self.commands, list(auto_scan.keys()))
        self.session = PromptSession(completer=self.completer)
        # state variables
        self._csv: Path = None
        self._alias: Path = None
        self.data: dict[ID, dict[str, str]] = {}
        self.alias_data: list[str] = None
        self.modified_log: dict[ID, Stuffs] = {}
        self.alias_log: list[tuple[tuple[str, str], IssueId]] = []
        self.encoding: str = None

    def run(self):
        print(
            """æ¬¢è¿ä½¿ç”¨ University Information Editor CLIã€‚
è¾“å…¥ help æˆ– ? æŸ¥çœ‹å‘½ä»¤ã€‚
è¾“å…¥ exit / Ctrl-D é€€å‡ºç¨‹åºï¼ŒCtrl-C å¼€å§‹æ–°çš„å¾ªç¯ã€‚"""
        )
        while True:
            self.completer.update_files(list(auto_scan.keys()))
            try:
                line = self.session.prompt('(editor) ')
            except KeyboardInterrupt:
                # Ctrl-C â€” ä¸­æ–­å½“å‰è¾“å…¥ï¼Œç»§ç»­å¾ªç¯
                print('^C')
                continue
            except EOFError:
                print('\né€€å‡ºç¨‹åºã€‚')
                break
            if not line.strip():
                continue
            lines = line.splitlines()
            for line in lines:
                line = line.strip()
                i = line.find(' ')
                if i == -1:
                    cmd, arg_str = line, ''
                else:
                    cmd, arg_str = line[:i], line[i + 1 :].strip()

                match cmd.lower():
                    case 'load':
                        self.do_load(arg_str)
                    case 'dump':
                        self.do_dump(arg_str)
                    case 'alias':
                        self.do_alias(arg_str)
                    case 'del':
                        self.do_del(arg_str)
                    case 'outdate':
                        self.do_outdate(arg_str)
                    case 'generate':
                        self.do_generate()
                    case 'exit':
                        return
                    case 'view':
                        self.do_view(arg_str)
                    case 'help' | '?' | 'ï¼Ÿ':
                        self.do_help()
                    case _:
                        logger.warning(f'æœªçŸ¥å‘½ä»¤: {cmd}')

    def do_help(self):
        print('å‘½ä»¤åˆ—è¡¨:')

        width = max(len(cmd) for cmd, _ in commands) + 2
        for cmd, desc in commands:
            print(f'  {cmd.ljust(width)}-- {desc}')

    def do_load(self, arg: str):
        def load_csv():
            with open(self._csv, 'rb') as f:
                chunk = f.read(1000)
                encoding = chardet.detect(chunk)['encoding']
            self.encoding = encoding
            logger.warning(f'CSV æ–‡ä»¶åŠ è½½ä¸­ï¼Œç¼–ç : {encoding}')
            with self._csv.open(newline='', encoding=encoding, errors='ignore') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    self.data[row['ç­”é¢˜åºå·']] = row
            logger.info(f'CSV æ–‡ä»¶åŠ è½½å®Œæˆï¼Œæ•°æ®æ¡ç›®æ•°: {len(self.data)}')

        def load_alias():
            with self._alias.open(encoding='utf-8') as f:
                self.alias_data = f.read().splitlines()
            logger.info(f'åˆ«åæ–‡ä»¶åŠ è½½å®Œæˆï¼Œæ•°æ®æ¡ç›®æ•°: {len(self.alias_data)}')

        parser = argparse.ArgumentParser(
            prog='load',
            description='åŠ è½½ä¸€ä¸ªæˆ–å¤šä¸ªæ•°æ®æ–‡ä»¶',
            add_help=False,
        )
        parser.add_argument(
            'files', nargs='*', type=Path, help='è¦åŠ è½½çš„æ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªï¼‰'
        )
        parsed = self.safe_parse(parser, arg)
        files: list[Path] = parsed.files
        match files:
            case []:
                try:
                    self._csv, self._alias = (
                        auto_scan['results_desensitized.csv'],
                        auto_scan['alias.txt'],
                    )
                except KeyError as e:
                    logger.error(
                        f'è‡ªåŠ¨åŠ è½½å‡ºé”™ï¼Œè¯·ç¡®ä¿å½“å‰ç›®å½•ä¸‹å­˜åœ¨ result_desensitized.csv å’Œ alias.txt {e!r}'
                    )
                    return

            case [data, alias] if data.suffix == '.csv' and alias.suffix == '.txt':
                self._csv, self._alias = data, alias

            case [alias, data] if data.suffix == '.csv' and alias.suffix == '.txt':
                self._csv, self._alias = data, alias
            case _:
                logger.error('å‚æ•°é”™è¯¯: éœ€è¦æä¾› 0 æˆ– 2 ä¸ªæ–‡ä»¶å‚æ•°')
                return
        logger.info(
            f'åŠ è½½æ–‡ä»¶: CSV = {smart_path(self._csv)}, Alias = {smart_path(self._alias)}'
        )
        load_csv()
        load_alias()

    # ---- dump: æ”¯æŒå¤šä¸ªç›®æ ‡æ–‡ä»¶ï¼ˆä½ç½®å‚æ•°ï¼‰ ----
    def do_dump(self, arg: str):
        def dump_csv(data: Path = self._csv):
            with open(data, 'w', newline='', encoding=self.encoding) as f:
                writer = csv.DictWriter(
                    f, fieldnames=self.data[next(iter(self.data))].keys()
                )
                writer.writeheader()  # å†™è¡¨å¤´
                writer.writerows(list(self.data.values()))  # å†™å¤šè¡Œå­—å…¸
            logger.info(f'CSV: å·²å†™å…¥{len(self.data)}è¡Œæ•°æ®')

        def dump_alias(alias: Path = self._alias):
            with open(alias, 'w', encoding='utf-8') as f:
                f.write('\n'.join(self.alias_data))
            logger.info(f'Alias: å·²å†™å…¥{len(self.alias_data)}è¡Œæ•°æ®')

        parser = argparse.ArgumentParser(
            prog='dump',
            description='å¯¼å‡ºä¸€ä¸ªæˆ–å¤šä¸ªæ•°æ®æ–‡ä»¶',
            add_help=False,
        )
        parser.add_argument(
            'files', nargs='*', type=Path, help='è¦å¯¼å‡ºçš„æ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªï¼‰'
        )
        parsed = self.safe_parse(parser, arg)
        if len(parsed.files) > 2:
            logger.error('å‚æ•°é”™è¯¯ï¼šæœ€å¤šåªèƒ½æä¾› 2 ä¸ªæ–‡ä»¶å‚æ•°')
            return
        files: list[Path] = parsed.files
        match files:
            case [data] if data.suffix == '.csv':
                dump_csv(data)
            case [data, alias] if data.suffix == '.csv' and alias.suffix == '.txt':
                dump_csv(data)
                dump_alias(alias)
            case [alias, data] if data.suffix == '.csv' and alias.suffix == '.txt':
                dump_csv(data)
                dump_alias(alias)
            case [alias] if alias.suffix == '.txt':
                dump_alias(alias)
            case []:
                dump_csv()
                dump_alias()
            case _:
                logger.debug(files)
                logger.error('æ–‡ä»¶åä¸æ­£ç¡®')
                return

    # ---- alias: oldname newname [issueId...] ----
    def do_alias(self, arg: str):
        parser = argparse.ArgumentParser(
            prog='alias',
            description='è®°å½•å­¦æ ¡æ›´å',
            add_help=False,
        )
        parser.add_argument('oldname', help='åŸå')
        parser.add_argument('newname', help='æ–°å')
        parser.add_argument('issueIds', nargs='*', help='å¯é€‰çš„ issueId(s)')
        parsed = self.safe_parse(parser, arg)
        if not parsed:
            return
        self.alias_data.append(f'{parsed.oldname}ğŸš®{parsed.newname}')
        self.alias_log.append(
            ((parsed.oldname, parsed.newname), parsed.issueIds)
            if parsed.issueIds
            else ((parsed.oldname, parsed.newname), None)
        )
        logger.info(
            f'æ·»åŠ åˆ«å {parsed.oldname} -> {parsed.newname}ï¼ŒissueIds={parsed.issueIds}'
        )

    def do_del(self, arg: str):
        parser = argparse.ArgumentParser(
            prog='del',
            add_help=False,
        )
        parser.add_argument('id', help='è®°å½• ID')
        parser.add_argument('issueIds', nargs='*', type=str, help='å¯é€‰çš„ issueId(s)')
        parsed = self.safe_parse(parser, arg)
        if not parsed:
            return
        if parsed.id not in self.data:
            logger.error(f'è®°å½• ID {parsed.id} ä¸å­˜åœ¨')
            return
        del self.data[parsed.id]
        self.modified_log[parsed.id] = Stuffs(parsed.issueIds, 'del')
        logger.info(f'åˆ é™¤å›ç­” {parsed.id}ï¼ŒissueIds={parsed.issueIds}')

    def do_view(self, arg: str):
        def vertical_table(fields: list[str], rows: list[list[str]]):
            table = Table(show_header=False, box=None)

            # ç¬¬ä¸€åˆ—æ˜¯å­—æ®µå
            table.add_column('å­—æ®µ', style='bold')

            # æ·»åŠ æ¯ä¸€è¡Œä½œä¸ºåˆ—
            for i, _ in enumerate(rows):
                table.add_column(f'{i}', style='dim')

            # æ¯ä¸€å­—æ®µå¯¹åº”æ¯åˆ—çš„å€¼
            for idx, field in enumerate(fields):
                values = [row[idx] if idx < len(row) else '' for row in rows]
                table.add_row(field, *values)

            Console().print(table)

        parser = argparse.ArgumentParser(
            prog='view',
            add_help=False,
        )
        parser.add_argument('ids', nargs='+', help='è®°å½• ID(s)')
        parsed = self.safe_parse(parser, arg)

        if not parsed:
            return
        logger.warning('ä½ å¯èƒ½éœ€è¦æ‰‹åŠ¨è°ƒèŠ‚ç»ˆç«¯å­—ä½“å¤§å°')
        cols = ['ID'] + [f'{i}' for i in range(5, 30)]
        rows = []
        for id in parsed.ids:
            if id not in self.data:
                logger.error(f'è®°å½• ID {id} ä¸å­˜åœ¨')
                return

            rows.append([id, *[self.data[id].get(f'Q{i}', '') for i in range(5, 30)]])
        vertical_table(cols, rows)

    def do_outdate(self, arg: str):
        parser = argparse.ArgumentParser(
            prog='outdate',
            add_help=False,
        )
        parser.add_argument('id', help='è®°å½• ID')
        parser.add_argument('issueIds', nargs='*', type=int, help='å¯é€‰çš„ issueId(s)')
        parsed = self.safe_parse(parser, arg)
        if not parsed:
            return
        if parsed.id not in self.data:
            logger.error(f'è®°å½• ID {parsed.id} ä¸å­˜åœ¨')
            return
        for i in range(5, 30):
            self.data[parsed.id]['Q' + str(i)] = (
                '[è¿‡æ—¶]ï¼š' + self.data[parsed.id]['Q' + str(i)]
            )
        self.modified_log[parsed.id] = Stuffs(parsed.issueIds, 'outdate')
        logger.info(f'æ ‡è®°è¿‡æœŸ {parsed.id}, issueIds={parsed.issueIds}')

    @staticmethod
    def safe_parse(parser: argparse.ArgumentParser, arg_str: str):
        try:
            return parser.parse_args(shlex.split(arg_str))
        except SystemExit:
            pass

    def do_generate(self):
        DELETED = 'åˆ é™¤äº†A{id}|ï¼Œç”±äº{issue_ids}çš„åé¦ˆ'
        OUTDATED = 'å°†A{id}æ ‡è®°ä¸ºè¿‡æœŸ|ï¼Œç”±äº{issue_ids}çš„åé¦ˆ'
        ADDED = 'æ·»åŠ äº†æ–°çš„åˆ«åï¼Œ{old_name} -> {new_name}|ï¼Œç”±äº{issue_ids}çš„åé¦ˆ'
        TEMPLATE = """# ä¿®æ”¹æ—¥å¿—
ä»¥ä¸‹æ˜¯æ­¤PRçš„ä¿®æ”¹è®°å½•ï¼š
## åˆ é™¤è®°å½•
{deleted}
## æ ‡è®°è¿‡æ—¶
{outdated}
## æ·»åŠ åˆ«å
{added}
"""
        deleted = []
        outdated = []
        added = []
        for id, stuff in self.modified_log.items():
            if stuff.changed == 'del':
                if not stuff.issue_ids:
                    deleted.append(
                        re.sub(r'\|.*', '', DELETED.format(id=id, issue_ids=''))
                    )
                    continue
                deleted.append(
                    DELETED.format(
                        id=id, issue_ids=','.join(f' #{i} ' for i in stuff.issue_ids)
                    ).replace('|', '')
                )
            elif stuff.changed == 'outdate':
                if not stuff.issue_ids:
                    outdated.append(
                        re.sub(r'\|.*', '', OUTDATED.format(id=id, issue_ids=''))
                    )
                    continue
                outdated.append(
                    OUTDATED.format(
                        id=id, issue_ids=','.join(f' #{i} ' for i in stuff.issue_ids)
                    ).replace('|', '')
                )
        logger.debug(self.alias_log)
        for name, issue_ids in self.alias_log:
            old_name, new_name = name
            if not issue_ids:
                added.append(
                    re.sub(
                        r'\|.*',
                        '',
                        ADDED.format(
                            old_name=old_name, new_name=new_name, issue_ids=''
                        ),
                    )
                )
                continue
            added.append(
                ADDED.format(
                    old_name=old_name,
                    new_name=new_name,
                    issue_ids=','.join(f' #{i} ' for i in issue_ids),
                ).replace('|', '')
            )
        logger.info(
            TEMPLATE.format(
                deleted='\n'.join(deleted) if deleted else 'æ— ',
                outdated='\n'.join(outdated) if outdated else 'æ— ',
                added='\n'.join(added) if added else 'æ— ',
            )
        )


def run():
    cli = UniInfoCLI()
    cli.run()


logger = setup_logger()
auto_scan = scan_folders()
if __name__ == '__main__':
    run()
